{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d3e779-d936-424c-8c1e-635d680f625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f137bc4-2d5b-402d-aff3-f8a225176fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sms_spam.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfddd94-5e7b-4aea-bc52-44b0d6b743a7",
   "metadata": {},
   "source": [
    "**Proccessing the Data before training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "120e4099-48df-4a2b-9476-1c92e53bb6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13406317300789664\n",
      "0.8659368269921034\n"
     ]
    }
   ],
   "source": [
    "#create an array that is 0 if ham and 1 if spam\n",
    "labels = (df[\"label\"]==\"spam\").astype(int)\n",
    "\n",
    "stopwords = [\"the\", \"and\", \"is\", \"in\", \"to\", \"a\", \"of\", \"i\", \"you\", \"u\", \"me\", \"it\", \"for\", \"your\", \"my\"]\n",
    "#lower to lowercase a string, str to apply it to all strings in the column\n",
    "X_texts = df[\"message\"].str.lower()\n",
    "\n",
    "#replace any characters that are not a-z or 0-9\n",
    "X_texts = X_texts.replace(r'\\W+', \" \", regex=True)\n",
    "\n",
    "#split words and remove any stopwords\n",
    "X_texts  = [text.split() for text in X_texts]\n",
    "X_texts = [[w for w in text if w not in stopwords] for text in X_texts]\n",
    "\n",
    "#create a dictionary that counts the instances of each word in X_texts\n",
    "vocab = Counter()\n",
    "[vocab.update(text) for text in X_texts]\n",
    "\n",
    "#create a dict of the most common words as keys and index as value\n",
    "vocab = {word:idx for idx, (word,__) in enumerate(vocab.most_common(3000))}\n",
    "\n",
    "#create an array of vectors to show how many times a word from vocab appears in each message\n",
    "X_data = [[0]*len(vocab) for i in range(len(X_texts))] ##array of vectors of 0s as initialization\n",
    "for i, text in enumerate(X_texts):\n",
    "    for word in text: \n",
    "        if(word in vocab):\n",
    "            X_data[i][vocab[word]]=+1\n",
    "print(len(df[df[\"label\"]==\"spam\"])/len(df))\n",
    "print(len(df[df[\"label\"]==\"ham\"])/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4815a4-3ea8-4bc7-882a-e16a0a4ddd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def init_weights(n_features):\n",
    "    return np.zeros(n_features), 0.0\n",
    "\n",
    "def predict(X, W, b, threshold=0.5):\n",
    "    linear = np.dot(X, W) +b\n",
    "    pred = sigmoid(linear)\n",
    "    return(pred >= threshold).astype(int)\n",
    "\n",
    "def train(X_train, Y_train, lr=0.01, epochs=1000):\n",
    "    W,b = init_weights(len(vocab))\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        Y_pred = sigmoid(np.dot(X_train,W) + b)\n",
    "        \n",
    "        dw = np.dot(X_train.T, (Y_pred - Y_train)) / len(X_train)\n",
    "        db = np.sum(Y_pred-Y_train) / len(X_train)\n",
    "        \n",
    "        W -= lr * dw\n",
    "        b -= lr * db\n",
    "    return W, b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ecdd937-33ae-4fc1-ac0e-ac1fa3022741",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.array(X_data)  #Is an array of vectors, the array index corresponds to a message, and each vector index corresponds to stopword, each value in the vector is the number of times the word appeared in the message\n",
    "Y_data = np.array(labels)  #Spam or ham labels corresponding to the messages\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, stratify=Y_data, test_size = 0.2)\n",
    "\n",
    "W, b = train(X_train, Y_train, lr=0.15, epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba61a37-3f9c-418f-a26c-d28372a90c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.60806653 -0.47810018  0.01217579 ... -0.00534177 -0.00931403\n",
      " -0.00667397] -2.965970562977659\n"
     ]
    }
   ],
   "source": [
    "Y_test_predict = predict(X_test, W, b, threshold=0.5)\n",
    "print(W, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b83f80c9-a364-45e1-a799-4abde84718bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9918032786885246\n",
      "Recall: 0.8120805369127517\n",
      "F1 Score: 0.8929889298892989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Precision:\", precision_score(Y_test, Y_test_predict))\n",
    "print(\"Recall:\", recall_score(Y_test, Y_test_predict))\n",
    "print(\"F1 Score:\", f1_score(Y_test, Y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "823181c3-4c8f-41e8-953e-d216b274c57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[965   1]\n",
      " [ 28 121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.972     0.999     0.985       966\n",
      "           1      0.992     0.812     0.893       149\n",
      "\n",
      "    accuracy                          0.974      1115\n",
      "   macro avg      0.982     0.906     0.939      1115\n",
      "weighted avg      0.974     0.974     0.973      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(confusion_matrix(Y_test, Y_test_predict))\n",
    "print(classification_report(Y_test, Y_test_predict, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9799fa75-a304-4bc9-ae7f-79ca0e397fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
